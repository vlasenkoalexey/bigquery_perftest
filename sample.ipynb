{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "project_id = !gcloud config list --format 'value(core.project)' | head -n 1\n",
    "project_id = project_id[0]\n",
    "project_id"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'alekseyv-gke'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from absl import app\n",
    "from absl import flags\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import numpy\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "from tensorflow_io.bigquery import BigQueryReadSession\n",
    "\n",
    "DATASET_GCP_PROJECT_ID = \"bigquery-public-data\"\n",
    "DATASET_ID = \"samples\"\n",
    "TABLE_ID = \"wikipedia\"\n",
    "requested_streams = 2\n",
    "sloppy = True\n",
    "batch_size = 32\n",
    "\n",
    "client = BigQueryClient()\n",
    "read_session = client.read_session(\n",
    "  \"projects/\" + project_id,\n",
    "  DATASET_GCP_PROJECT_ID, TABLE_ID, DATASET_ID,\n",
    "  [\"title\",\n",
    "   \"id\",\n",
    "   \"num_characters\",\n",
    "   \"language\",\n",
    "   \"timestamp\",\n",
    "   \"wp_namespace\",\n",
    "   \"contributor_username\"],\n",
    "  [dtypes.string,\n",
    "   dtypes.int64,\n",
    "   dtypes.int64,\n",
    "   dtypes.string,\n",
    "   dtypes.int64,\n",
    "   dtypes.int64,\n",
    "   dtypes.string],\n",
    "  requested_streams=requested_streams\n",
    "  )\n",
    "\n",
    "streams = read_session.get_streams()\n",
    "print('Requested %d streams, BigQuery returned %d streams' % (\n",
    "    requested_streams\n",
    "    len(streams)))\n",
    "dataset = read_session.parallel_read_rows(sloppy=sloppy).batch(batch_size)\n",
    "row_index = 0\n",
    "for row in dataset.prefetch(10).take(10):\n",
    "    print(\"row %d: %s\" % (row_index, row))\n",
    "    row_index += 1\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from absl import app\n",
    "from absl import flags\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import numpy\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "from tensorflow_io.bigquery import BigQueryReadSession\n",
    "\n",
    "DATASET_GCP_PROJECT_ID = \"bigquery-public-data\"\n",
    "DATASET_ID = \"samples\"\n",
    "TABLE_ID = \"wikipedia\"\n",
    "requested_streams = 2\n",
    "sloppy = True\n",
    "batch_size = 32\n",
    "\n",
    "client = BigQueryClient()\n",
    "read_session = client.read_session(\n",
    "  \"projects/\" + project_id,\n",
    "  DATASET_GCP_PROJECT_ID, TABLE_ID, DATASET_ID,\n",
    "  [\"title\",\n",
    "   \"id\",\n",
    "   \"num_characters\",\n",
    "   \"language\",\n",
    "   \"timestamp\",\n",
    "   \"wp_namespace\",\n",
    "   \"contributor_username\"],\n",
    "  [dtypes.string,\n",
    "   dtypes.int64,\n",
    "   dtypes.int64,\n",
    "   dtypes.string,\n",
    "   dtypes.int64,\n",
    "   dtypes.int64,\n",
    "   dtypes.string],\n",
    "  requested_streams=requested_streams\n",
    "  )\n",
    "\n",
    "streams = read_session.get_streams()\n",
    "print('Requested %d streams, BigQuery returned %d streams' % (\n",
    "    requested_streams,\n",
    "    len(streams)))\n",
    "\n",
    "def read_rows(stream):\n",
    "    dataset = read_session.read_rows(stream)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "streams = read_session.get_streams()\n",
    "streams_count=len(streams)\n",
    "streams_ds = tf.data.Dataset.from_tensor_slices(streams)\n",
    "dataset = streams_ds.interleave(\n",
    "    read_rows,\n",
    "    cycle_length=streams_count,\n",
    "    num_parallel_calls=streams_count,\n",
    "    deterministic=False)\n",
    "\n",
    "row_index = 0\n",
    "for row in dataset.prefetch(10).take(10):\n",
    "    print(\"row %d: %s\" % (row_index, row))\n",
    "    row_index += 1\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!python sample.py --project_id=$project_id"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!docker build --build-arg BASE_IMAGE=tensorflow/tensorflow:2.5.0 --build-arg TF_IO=tensorflow-io==0.19.1 -f Dockerfile -t tf2.5 . && docker run -v ${PWD}:/v tf2.3 python3 /v/sample.py --project_id='alekseyv-gke'\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!docker build --build-arg BASE_IMAGE=tensorflow/tensorflow:2.3.0 --build-arg TF_IO=tensorflow-io==0.15.0 -f Dockerfile -t tf2.3 . && docker run -v ${PWD}:/v tf2.3 python3 /v/bq_perftest_mult_columns.py --project_id=alekseyv-gke --batch_size=2048 --num_iterations=100 --mini_batch_size=10 --num_columns=120 --requested_streams=1 --sloppy=true --format=AVRO\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}